{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2850d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "def scrape_trendyol_data(pages):\n",
    "    data = []\n",
    "    base_url = \"https://www.trendyol.com\"\n",
    "\n",
    "    for page in range(1, pages + 1):\n",
    "        try:\n",
    "            url = f\"{base_url}/cep-telefonu-x-c103498?pi={page}\"\n",
    "            response = requests.get(url)\n",
    "            soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "            products = soup.find_all(\"div\", class_=\"p-card-wrppr with-campaign-view\")\n",
    "\n",
    "            for product in products:\n",
    "                try:\n",
    "                    # Ürün Linki\n",
    "                    product_href = product.a.get(\"href\")\n",
    "                    full_link = base_url + product_href\n",
    "\n",
    "                    # Ürün ID\n",
    "                    product_id = product.get(\"data-id\")\n",
    "\n",
    "                    # Favori Sayısı\n",
    "                    favorite_span = product.select_one(\"span.focused-text\")\n",
    "                    favorite_count = favorite_span.text.strip().replace(\" kişi\", \"\") if favorite_span else \"0\"\n",
    "\n",
    "                    # Ürün detay sayfasına git\n",
    "                    r1 = requests.get(full_link)\n",
    "                    soup1 = BeautifulSoup(r1.content, \"lxml\")\n",
    "\n",
    "                    # Ürün adı\n",
    "                    info_title_folder = soup1.find(\"h1\", class_=\"pr-new-br\")\n",
    "                    info_name = info_title_folder.find(\"span\").text.strip() if info_title_folder else \"Null\"\n",
    "\n",
    "                    # Marka\n",
    "                    info_brand = info_title_folder.find(\"a\", class_=\"product-brand-name-with-link\") if info_title_folder else None\n",
    "                    brand_text = info_brand.text.strip() if info_brand else \"Null\"\n",
    "\n",
    "                    # Fiyat\n",
    "                    price_div = soup1.find(\"div\", class_=\"pr-bx-nm with-org-prc\")\n",
    "                    price_text = price_div.text.strip() if price_div else \"Null\"\n",
    "\n",
    "                    # Puan\n",
    "                    rating_div = soup1.find(\"div\", class_=\"rating-score\")\n",
    "                    rating = rating_div.text.strip() if rating_div else \"Yok\"\n",
    "\n",
    "                    # Ürün açıklaması\n",
    "                    description_div = soup1.find(\"div\", class_=\"product-detail-content\")\n",
    "                    description_text = description_div.text.strip() if description_div else \"Yok\"\n",
    "\n",
    "                    # Diğer Özellikler\n",
    "                    attributes_dict = {}\n",
    "                    attributes_section = soup1.find(\"div\", class_=\"attributes\")\n",
    "                    if attributes_section:\n",
    "                        for attr in attributes_section.find_all(\"li\"):\n",
    "                            try:\n",
    "                                attr_name = attr.find(\"span\", class_=\"attribute-label attr-name\").text.strip()\n",
    "                                attr_value_tag = attr.find(\"span\", class_=\"attribute-value\")\n",
    "                                if attr_value_tag:\n",
    "                                    attr_value = attr_value_tag.get_text(separator=\" \").strip()\n",
    "                                    attributes_dict[attr_name] = attr_value\n",
    "                            except Exception as e:\n",
    "                                print(f\"Özellik ayrıştırılamadı: {e}\")\n",
    "\n",
    "                    \n",
    "                    data.append({\n",
    "                        \"Ürün ID\": product_id,\n",
    "                        \"Ürün adı\": info_name,\n",
    "                        \"Marka\": brand_text,\n",
    "                        \"Fiyat\": price_text,\n",
    "                        \"Favori Sayısı\": favorite_count,\n",
    "                        \"Puan\": rating,\n",
    "                        \"Açıklama\": description_text,\n",
    "                        \"Ürün Linki\": full_link,\n",
    "                        **attributes_dict\n",
    "                    })\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"[ÜRÜN HATASI] {e}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[SAYFA HATASI] {e}\")\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "veriler = scrape_trendyol_data(10)  \n",
    "df = pd.DataFrame(veriler)\n",
    "df.to_csv(\"cep_telefonu.csv\", index=False, encoding=\"utf-8-sig\")  # Türkçe karakterler için utf-8-sig\n",
    "print(\"Veriler CSV dosyasına kaydedildi.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7aa76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "def scrape_trendyol_data(pages):\n",
    "    data = []\n",
    "    base_url = \"https://www.trendyol.com\"\n",
    "\n",
    "    for page in range(1, pages + 1):\n",
    "        try:\n",
    "            url = f\"{base_url}/televizyon-x-c104156?pi={page}\"\n",
    "            response = requests.get(url)\n",
    "            response.encoding = response.apparent_encoding  # Sayfanın doğru encoding'ini tespit et\n",
    "            soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "            products = soup.find_all(\"div\", class_=\"p-card-wrppr with-campaign-view\")\n",
    "\n",
    "            for product in products:\n",
    "                try:\n",
    "                    # Ürün Linki\n",
    "                    product_href = product.a.get(\"href\")\n",
    "                    full_link = base_url + product_href\n",
    "\n",
    "                    # Ürün ID\n",
    "                    product_id = product.get(\"data-id\")\n",
    "\n",
    "                    # Favori Sayısı\n",
    "                    favorite_span = product.select_one(\"span.focused-text\")\n",
    "                    favorite_count = favorite_span.text.strip().replace(\" kişi\", \"\") if favorite_span else \"0\"\n",
    "\n",
    "                    # Ürün detay sayfasına git\n",
    "                    r1 = requests.get(full_link)\n",
    "                    r1.encoding = r1.apparent_encoding  # Detay sayfasının encoding'ini tespit et\n",
    "                    soup1 = BeautifulSoup(r1.content, \"lxml\")\n",
    "\n",
    "                    # Ürün adı\n",
    "                    info_title_folder = soup1.find(\"h1\", class_=\"pr-new-br\")\n",
    "                    info_name = info_title_folder.find(\"span\").text.strip() if info_title_folder else \"Null\"\n",
    "\n",
    "                    # Marka\n",
    "                    info_brand = info_title_folder.find(\"a\", class_=\"product-brand-name-with-link\") if info_title_folder else None\n",
    "                    brand_text = info_brand.text.strip() if info_brand else \"Null\"\n",
    "\n",
    "                    # Fiyat\n",
    "                    price_div = soup1.find(\"div\", class_=\"pr-bx-nm with-org-prc\")\n",
    "                    price_text = price_div.text.strip() if price_div else \"Null\"\n",
    "\n",
    "                    # Puan \n",
    "                    rating_div = soup1.find(\"div\", class_=\"rating-score\")\n",
    "                    rating = rating_div.text.strip() if rating_div else \"Yok\"\n",
    "\n",
    "                    # Ürün açıklaması \n",
    "                    description_div = soup1.find(\"div\", class_=\"product-detail-content\")\n",
    "                    description_text = description_div.text.strip() if description_div else \"Yok\"\n",
    "\n",
    "                    # Kala Özellikler(Bu kısımlarda alabildiğimiz her özelliği almaya çalışıyoruz)\n",
    "                    #Bu kısımı kullanmak istenmezse kapatılabilir\n",
    "                    attributes_dict = {}\n",
    "                    attributes_section = soup1.find(\"div\", class_=\"attributes\")\n",
    "                    if attributes_section:\n",
    "                        for attr in attributes_section.find_all(\"li\"):\n",
    "                            try:\n",
    "                                attr_name = attr.find(\"span\", class_=\"attribute-label attr-name\").text.strip()\n",
    "                                attr_value_tag = attr.find(\"span\", class_=\"attribute-value\")\n",
    "                                if attr_value_tag:\n",
    "                                    attr_value = attr_value_tag.get_text(separator=\" \").strip()\n",
    "                                    attributes_dict[attr_name] = attr_value\n",
    "                            except Exception as e:\n",
    "                                print(f\"Özellik ayrıştırılamadı: {e}\")\n",
    "\n",
    "                                \n",
    "                    data.append({\n",
    "                        \"Ürün ID\": product_id,\n",
    "                        \"Ürün adı\": info_name,\n",
    "                        \"Marka\": brand_text,\n",
    "                        \"Fiyat\": price_text,\n",
    "                        \"Favori Sayısı\": favorite_count,\n",
    "                        \"Puan\": rating,\n",
    "                        \"Açıklama\": description_text,\n",
    "                        \"Ürün Linki\": full_link,\n",
    "                        **attributes_dict\n",
    "                    })\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"[ÜRÜN HATASI] {e}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[SAYFA HATASI] {e}\")\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "veriler = scrape_trendyol_data(10)  \n",
    "df = pd.DataFrame(veriler)\n",
    "df.to_csv(\"televizyon.csv\", index=False, encoding=\"utf-8-sig\")  # Türkçe karakterler için utf-8-sig\n",
    "print(\"Veriler CSV dosyasına kaydedildi.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee76fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "def scrape_trendyol_data(pages):\n",
    "    data = []\n",
    "    base_url = \"https://www.trendyol.com\"\n",
    "\n",
    "    for page in range(1, pages + 1):\n",
    "        try:\n",
    "            url = f\"{base_url}/kulaklik-x-c92?pi={page}\"\n",
    "            response = requests.get(url)\n",
    "            response.encoding = response.apparent_encoding  # Sayfanın doğru encoding'ini tespit et\n",
    "            soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "            products = soup.find_all(\"div\", class_=\"p-card-wrppr with-campaign-view\")\n",
    "\n",
    "            for product in products:\n",
    "                try:\n",
    "                    # Ürün Linki\n",
    "                    product_href = product.a.get(\"href\")\n",
    "                    full_link = base_url + product_href\n",
    "\n",
    "                    # Ürün ID\n",
    "                    product_id = product.get(\"data-id\")\n",
    "\n",
    "                    # Favori Sayısı\n",
    "                    favorite_span = product.select_one(\"span.focused-text\")\n",
    "                    favorite_count = favorite_span.text.strip().replace(\" kişi\", \"\") if favorite_span else \"0\"\n",
    "\n",
    "                    # Ürün detay sayfasına git\n",
    "                    r1 = requests.get(full_link)\n",
    "                    r1.encoding = r1.apparent_encoding  # Detay sayfasının encoding'ini tespit et\n",
    "                    soup1 = BeautifulSoup(r1.content, \"lxml\")\n",
    "\n",
    "                    # Ürün adı\n",
    "                    info_title_folder = soup1.find(\"h1\", class_=\"pr-new-br\")\n",
    "                    info_name = info_title_folder.find(\"span\").text.strip() if info_title_folder else \"Null\"\n",
    "\n",
    "                    # Marka\n",
    "                    info_brand = info_title_folder.find(\"a\", class_=\"product-brand-name-with-link\") if info_title_folder else None\n",
    "                    brand_text = info_brand.text.strip() if info_brand else \"Null\"\n",
    "\n",
    "                    # Fiyat\n",
    "                    price_div = soup1.find(\"div\", class_=\"pr-bx-nm with-org-prc\")\n",
    "                    price_text = price_div.text.strip() if price_div else \"Null\"\n",
    "\n",
    "                    # Puan \n",
    "                    rating_div = soup1.find(\"div\", class_=\"rating-score\")\n",
    "                    rating = rating_div.text.strip() if rating_div else \"Yok\"\n",
    "\n",
    "                    # Ürün açıklaması \n",
    "                    description_div = soup1.find(\"div\", class_=\"product-detail-content\")\n",
    "                    description_text = description_div.text.strip() if description_div else \"Yok\"\n",
    "\n",
    "                    # Diğer Özellikler\n",
    "                    attributes_dict = {}\n",
    "                    attributes_section = soup1.find(\"div\", class_=\"attributes\")\n",
    "                    if attributes_section:\n",
    "                        for attr in attributes_section.find_all(\"li\"):\n",
    "                            try:\n",
    "                                attr_name = attr.find(\"span\", class_=\"attribute-label attr-name\").text.strip()\n",
    "                                attr_value_tag = attr.find(\"span\", class_=\"attribute-value\")\n",
    "                                if attr_value_tag:\n",
    "                                    attr_value = attr_value_tag.get_text(separator=\" \").strip()\n",
    "                                    attributes_dict[attr_name] = attr_value\n",
    "                            except Exception as e:\n",
    "                                print(f\"Özellik ayrıştırılamadı: {e}\")\n",
    "\n",
    "                    # Veriyi listeye ekle\n",
    "                    data.append({\n",
    "                        \"Ürün ID\": product_id,\n",
    "                        \"Ürün adı\": info_name,\n",
    "                        \"Marka\": brand_text,\n",
    "                        \"Fiyat\": price_text,\n",
    "                        \"Favori Sayısı\": favorite_count,\n",
    "                        \"Puan\": rating,\n",
    "                        \"Açıklama\": description_text,\n",
    "                        \"Ürün Linki\": full_link,\n",
    "                        **attributes_dict\n",
    "                    })\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"[ÜRÜN HATASI] {e}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[SAYFA HATASI] {e}\")\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "veriler = scrape_trendyol_data(10)  \n",
    "df = pd.DataFrame(veriler)\n",
    "df.to_csv(\"kulaklık.csv\", index=False, encoding=\"utf-8-sig\")  # Türkçe karakterler için utf-8-sig\n",
    "print(\"Veriler CSV dosyasına kaydedildi.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a180d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "xx= pd.read_csv(\"televizyon.csv\")\n",
    "xx.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daeebf87",
   "metadata": {},
   "outputs": [],
   "source": [
    "xx= pd.read_csv(\"cep_telefonu.csv\")\n",
    "xx.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74521e25",
   "metadata": {},
   "source": [
    "# Cep telefonu ve Kulaklık için olan veri kullanılmadı."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
